{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create a library of randomly generated non-linear functions. These are to be estimated a) with all possible kernels in the library or b) with exponential kernels only (this will probably present a problem with extrapolation). Of course, we are talking only about 1-layer realtionship, because we don't do deep learning.\n",
    "\n",
    "The random functions are to be estimated from a given set of kernels, and will be constructed from multiple data views (design matrices). Do we know these groupings in practice? Possibly. Should the scope of a function be limited to within the dataset only? Yes. \n",
    "\n",
    "What about the generation of weights? This is important to argue the MKL part. They are to be generated along with the function and stored in the same object.\n",
    "\n",
    "Can a data view be sampled multiple times? No, because this will heavily obstruct the evaluation.\n",
    "\n",
    "For each term in the *sum* we randomly sample:\n",
    "- A data view\n",
    "- A subset of indices of the data view's columns. These will be part of an aggregation function.\n",
    "- A function family to operate on the data view.\n",
    "\n",
    "\n",
    "A similar experiment shall be repeated for the case where functions are performed on the same data view (possibly using all incides), but with kernels with different hyperparameters.\n",
    "\n",
    "A similar experiment can be done when the signals are generate from a sum of kernels with different weights and regression is performed wia dual coefficients. The, we should use the relationship between primal and dual weights to compare the values. Again, repeat for the cases where function family is known and unknown.\n",
    "\n",
    "How to treat different values of hyperparameters? Maybe the solution is something like grid search, trying with multiple kernel functions with different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.functions import MultiKernelFunction\n",
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "\n",
    "from mklaren.mkl.mklaren import Mklaren\n",
    "from mklaren.regression.ridge import RidgeLowRank\n",
    "from mklaren.kernel.kinterface import Kinterface\n",
    "import itertools as it\n",
    "\n",
    "import sklearn.metrics as skm\n",
    "mse = skm.mean_squared_error\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dimension\n",
    "P = 3\n",
    "p = 10\n",
    "n = 300\n",
    "\n",
    "# Data is generated randomly\n",
    "X = np.random.randn(n, p)\n",
    "\n",
    "# Dual coefficients are non-negative\n",
    "alpha = np.array([np.random.randn() for i in range(n)])\n",
    "\n",
    "mf = MultiKernelFunction(P)\n",
    "y = mf(X, alpha)\n",
    "y = y - y.mean()\n",
    "\n",
    "# Error of mean predictions\n",
    "rmse0 = (mse(y, np.zeros((n,))) / n) **0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mklaren model RMSE: 8193.970412, mean RMSE: 9024.341606. \n\nFunctional form:\ny = \n\t 2.11e-02 lin(x, x, ) + \n\t 1.62e-01 poly(x, x, p=5.00, b=-3.00) + \n\t 7.61e-03 exp(x, x, gamma=35.94)\n"
     ]
    }
   ],
   "source": [
    "# Fit this data using Mklaren\n",
    "mkl = Mklaren(delta=3, rank=12, lbd=0)\n",
    "Ks = [Kinterface(X, kernel=f) for (_, (f, _)) \n",
    "      in sorted(MultiKernelFunction.library.items())]\n",
    "mkl.fit(Ks, y)\n",
    "ypm = mkl.predict([X, X, X])\n",
    "\n",
    "rmse2 = (mse(y, ypm) / n) ** 0.5\n",
    "\n",
    "print(\"Mklaren model RMSE: %f, mean RMSE: %f. \\n\" % (rmse2, rmse0))\n",
    "print(\"Functional form:\")\n",
    "print(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare approximated and true weights from different families. \n",
    "The functions use different hyper parameters, hence the discrepancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exp', 'lin', 'poly']\n[       0.                0.          2839816.69588843]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(MultiKernelFunction.library.keys()))\n",
    "print(mkl.mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEHCAYAAACqbOGYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqSGwSBJavx/twKapnsh1GsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11007ac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(y, color=\"gray\")\n",
    "plt.title(\"Signal distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a target set of kernels in the library with all possible values of hyperparameters\n",
    "lib = MultiKernelFunction.library\n",
    "vals = MultiKernelFunction.values\n",
    "\n",
    "Ks = []\n",
    "for name, (f, pars) in lib.items():\n",
    "    if len(pars):\n",
    "        for p in pars:\n",
    "            for v in vals[p]:\n",
    "                k = Kinterface(data=X, kernel=f, kernel_args={p: v})\n",
    "                Ks.append(k)\n",
    "    else:\n",
    "        k = Kinterface(data=X, kernel=f)\n",
    "        Ks.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the MKL model to data and inspect weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkl = Mklaren(delta=12, rank=10, lbd=0)\n",
    "mkl.fit(Ks, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function poly_kernel at 0x10e7e88c0> {'p': 2} 205826.497301\n<function poly_kernel at 0x10e7e88c0> {'p': 3} 2127942.73785\n<function poly_kernel at 0x10e7e88c0> {'p': 4} 42095.9972035\n<function poly_kernel at 0x10e7e88c0> {'p': 5} 1365293.45226\n<function poly_kernel at 0x10e7e88c0> {'b': -3.0} 162991.413699\n<function exponential_kernel at 0x10e7e89b0> {'gamma': 0.01} 505120.701006\n"
     ]
    }
   ],
   "source": [
    "mu = mkl.mu\n",
    "inxs = mkl.mu.nonzero()[0]\n",
    "for i in inxs:\n",
    "    print Ks[i].kernel, Ks[i].kernel_args, mu[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}